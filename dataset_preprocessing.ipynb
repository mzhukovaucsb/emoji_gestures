{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8c434c8-af2e-4565-95dd-eee311225d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Importing necessary packages.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import preprocessor as p\n",
    "import emoji\n",
    "import regex\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f0225f3-c593-4bc4-ae54-fe46f4224bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Opening csv file as a DataFrame\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc36836-7cc5-4954-aa35-568671ada741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that the \"tweet\" column type is string \n",
    "df['tweet_original'] = df['tweet_original'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a9e47-2335-470c-83f7-1189028e624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns a list of hashtags for each tweet that contains hashtags.\n",
    "\"\"\"\n",
    "\n",
    "def hashtags(row):\n",
    "    text = row['tweet_original']\n",
    "    pat = re.compile(r\"#(\\w+)\")\n",
    "    return pat.findall(text)  \n",
    "\n",
    "df['hashtags'] = df.apply(hashtags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "144504f0-86b9-4fc4-a9c8-80951b4bd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Encodes user names combining the first 3 characters of the user name and the first 3 characters of the user's location.\n",
    "\"\"\"\n",
    "\n",
    "def encoding_username(row):\n",
    "    text1 = row['user']\n",
    "    text3 = row['location_encoded']\n",
    "    \n",
    "    encoded1 = text1[0:3]\n",
    "    encoded3 = text3[0:3]\n",
    "    encoded = encoded1 + encoded3\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "df['user_encoded'] = df.apply(encoding_username, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48014a-0385-4b5a-8912-fe4b7097bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns a list of all emoji that each tweet contains.\n",
    "\"\"\"\n",
    "\n",
    "def all_emoji_tweet(row):\n",
    "    text = row['tweet_original']\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "df['all_emoji'] = df.apply(all_emoji_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace46e91-4855-47fb-a1b2-a2b89ac50596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tweet features to tokenize (mentions, urls, and hashtags)\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG)\n",
    "\n",
    "\"\"\"\n",
    "    For each tweet, tokenizes hashtags, urls, and mentions.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_tweet(row):\n",
    "    text = row['tweet_original']\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = p.tokenize(text)\n",
    "   # text = text.replace(\"$MENTION$\", \"mention\")\n",
    "   # text = text.replace(\"$URL$\", \"url\")\n",
    "   # text = text.replace(\"$HASHTAG$\", \"hashtag\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486293a-063e-474e-bbcc-f45958f8c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Lowercasing for each tweet.\n",
    "\"\"\"\n",
    "\n",
    "def lowercase_tweet(row):\n",
    "    text = row['preprocess_tweet']\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc7087-4c5f-462d-97df-3983136499e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation marks\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation)) \n",
    "\n",
    "\"\"\"\n",
    "    Removes punctuation marks for each tweet.\n",
    "\"\"\"\n",
    "\n",
    "def remove_punct_tweet(row):\n",
    "    text = row['lowercase_tweet']\n",
    "    text = text.translate(table)  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206de1c-4a46-4cd1-9fba-bc3b2dfb59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting tokenizer that can tokenize emoji\n",
    "t = TweetTokenizer()\n",
    "\n",
    "\"\"\"\n",
    "    Tokenizes each tweet.\n",
    "\"\"\"\n",
    "\n",
    "def tokenize_tweet(row):\n",
    "    text = row['remove_punct_tweet']\n",
    "    text = t.tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367937d-b12e-4c1c-aba5-05bb20e119d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Puts all the stage of preprocessing together.\n",
    "\"\"\"\n",
    "\n",
    "def preprocessed(row):\n",
    "    text = row['tokenize_tweet']\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8914e4-f40a-49aa-9721-e306c98643f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    For each tweet, checks in the tweet contains urls.\n",
    "\"\"\"\n",
    "\n",
    "def url(row):\n",
    "    text = row['preprocessed']\n",
    "    substring = \"url\"\n",
    "    if substring in text: \n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "df['url_present'] = df.apply(url, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf79296-49c6-454e-b366-5cccb9da771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    For each tweet, checks in the tweet contains mentions.\n",
    "\"\"\"\n",
    "\n",
    "def mention(row):\n",
    "    text = row['preprocessed']\n",
    "    substring = \"mention\"\n",
    "    if substring in text: \n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "df['mention_present'] = df.apply(mention, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a026e0fb-9542-4c0d-8284-d0afc2b18faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    For each tweet, checks in the tweet contains hashtags.\n",
    "\"\"\"\n",
    "\n",
    "def hashtag(row):\n",
    "    text = row['preprocessed']\n",
    "    substring = \"hashtag\"\n",
    "    if substring in text: \n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "df['hashtag_present'] = df.apply(hashtag, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
